{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cffe1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class Node:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.label = None\n",
    "        self.decisionAttr = None\n",
    "        self.decisionGain = None\n",
    "        self.decisionValue = None\n",
    "        self.branches = []\n",
    "    def printTree(self):\n",
    "        self.printTreeRecurse(0)\n",
    "    def printTreeRecurse(self, level):\n",
    "        print ('\\t' * level + self.name),\n",
    "        if self.decisionAttr and self.decisionGain:\n",
    "            print ('split by ' + str(self.decisionAttr) + ' for a gain of ' + str(self.decisionGain)),\n",
    "        if self.label:\n",
    "            print (' ' + self.label),\n",
    "        #print ('\\n'),\n",
    "        level += 1\n",
    "        for branch in self.branches:\n",
    "            branch.printTreeRecurse(level)\n",
    "    def predictOutcome(self, cases, a):\n",
    "        predictions = []\n",
    "        for c in cases:\n",
    "            outcome = self.predictOutcomeRecurse(c, attributes)\n",
    "            predictions.append(outcome)\n",
    "        return predictions\n",
    "    def predictOutcomeRecurse(self, case, a):\n",
    "        if self.name == '':\n",
    "            # Leaf nodes\n",
    "            if self.label == '+':\n",
    "                return 'Yes'\n",
    "            elif self.label == '-':\n",
    "                return 'No'\n",
    "        index = a.index(self.decisionAttr)\n",
    "        if self.decisionValue == case[index]:\n",
    "            return self.branches[0].predictOutcomeRecurse(case, a)\n",
    "        if self.decisionGain:\n",
    "            # Traverse to the branch where branch.decisionValue is in the case\n",
    "            for b in self.branches:\n",
    "                if b.decisionValue == case[index]:\n",
    "                    return b.predictOutcomeRecurse(case, a)\n",
    "# Returns the root node of the constructed decision tree\n",
    "def constructDecisionTree(examples, targetAttribute, attributes):\n",
    "    root = Node('')\n",
    "\n",
    "    # Examples are all positive\n",
    "    # The last attribute in the example is\n",
    "\n",
    "    if all(isPositive(example[-1]) for example in examples):\n",
    "        root.label = '+'\n",
    "        return root\n",
    "\n",
    "    # Examples are all negative\n",
    "    elif all(not isPositive(example[-1]) for example in examples):\n",
    "        root.label = '-'\n",
    "        return root\n",
    "\n",
    "    # Attributes is empty\n",
    "    elif not attributes:\n",
    "        root.label = getMostCommonLabel(examples)\n",
    "        return root\n",
    "    else:\n",
    "        result = getHighestInfoGainAttr(attributes, examples)\n",
    "        attr = result[0]\n",
    "        gain = result[1]\n",
    "        attrIndex = result[2]\n",
    "\n",
    "        root.decisionAttr = attr\n",
    "        root.decisionGain = gain\n",
    "\n",
    "        possibleValues = uniqueValues(attrIndex, examples)\n",
    "\n",
    "        for value in possibleValues:\n",
    "            newBranch = Node(attr + ' = ' + value)\n",
    "            newBranch.decisionAttr = attr\n",
    "            newBranch.decisionValue = value\n",
    "            root.branches.append(newBranch)\n",
    "            branchExamples = sorted(row for row in examples if row[attrIndex] == value)\n",
    "\n",
    "            if not branchExamples:\n",
    "                leaf = Node(getMostCommonValue(targetAttribute, examples, possibleValues))\n",
    "                newBranch.branches.append(leaf)\n",
    "            else:\n",
    "                newExamples = []\n",
    "                for example in branchExamples:\n",
    "                    newExample = []\n",
    "                    for i in range(len(example)):\n",
    "                        if not i == attrIndex:\n",
    "                            newExample.append(example[i])\n",
    "                    newExamples.append(newExample)\n",
    "\n",
    "                newBranch.branches.append(constructDecisionTree(newExamples, targetAttribute, [a for a in attributes if not a == attr]))\n",
    "\n",
    "    return root\n",
    "\n",
    "\n",
    "# Determines whether a word is positive ('yes', 'true', etc.)\n",
    "def isPositive(word):\n",
    "    word = word.lower()\n",
    "    return word == 'yes' or word == 'true' or word == 'y' or word == 't'\n",
    "\n",
    "\n",
    "# Returns the most common label (+ or -) in the given list of nodes\n",
    "def getMostCommonLabel(nodes):\n",
    "    pCount = 0\n",
    "    nCount = 0\n",
    "\n",
    "    for node in nodes:\n",
    "        if node.label == '+':\n",
    "            pCount += 1\n",
    "        elif node.label == '-':\n",
    "            nCount += 1\n",
    "\n",
    "    if pCount >= nCount:\n",
    "        return '+'\n",
    "    else:\n",
    "        return '-'\n",
    "\n",
    "\n",
    "# Returns the attribute with the highest information gain, as well as the info gain value\n",
    "def getHighestInfoGainAttr(attributes, examples):\n",
    "    totalRows = len(examples)\n",
    "    # Divide examples into positive and negative\n",
    "    posExamples = sorted(row for row in examples if isPositive(row[-1]))\n",
    "    negExamples = sorted(row for row in examples if not isPositive(row[-1]))\n",
    "\n",
    "    # Get the expected info needed for the entire data set\n",
    "    allExpectedInfo = computeExpectedInfo(len(posExamples), len(negExamples))\n",
    "\n",
    "    valuesGain = []\n",
    "\n",
    "    # Compute the entropy & gain of each attribute\n",
    "    for i, attr in enumerate(attributes):\n",
    "\n",
    "        # Don't check the target attribute\n",
    "        if attributes[-1] == attributes[i]:\n",
    "            break\n",
    "\n",
    "        values = uniqueValues(i, examples)\n",
    "\n",
    "        # Lists for the expected info & probability of each value\n",
    "        valuesExpectedInfo = []\n",
    "        valuesProbability = []\n",
    "\n",
    "        # Compute the expected info needed for each value\n",
    "        for value in values:\n",
    "            # Count how many positive & negative examples there are for the value\n",
    "            posExamplesOfValue = sorted(row for row in posExamples if row[i]==value)\n",
    "            negExamplesOfValue = sorted(row for row in negExamples if row[i]==value)\n",
    "            numPos = len(posExamplesOfValue)\n",
    "            numNeg = len(negExamplesOfValue)\n",
    "            # Compute the expected info & probability of the value & add them to the lists\n",
    "            valueExpectedInfo = computeExpectedInfo(numPos, numNeg)\n",
    "            valueProbability = float(numPos + numNeg) / float(totalRows)\n",
    "            valuesExpectedInfo.append(valueExpectedInfo)\n",
    "            valuesProbability.append(valueProbability)\n",
    "\n",
    "        # Compute entropy & gain of value and add gain to the list\n",
    "        valueEntropy = computeEntropy(valuesExpectedInfo, valuesProbability)\n",
    "        valueGain = allExpectedInfo - valueEntropy\n",
    "        valuesGain.append(valueGain)\n",
    "\n",
    "    # The index of the attribute with the max gain\n",
    "    index = valuesGain.index(max(valuesGain))\n",
    "\n",
    "    return [attributes[index], valuesGain[index], index]\n",
    "\n",
    "\n",
    "# Returns the expected info needed\n",
    "# count1 is usually the number of positive examples\n",
    "# count2 is usually num of negative examples\n",
    "def computeExpectedInfo(count1, count2):\n",
    "    count1 = float(count1)\n",
    "    count2 = float(count2)\n",
    "    total = count1 + count2\n",
    "    prob1 = count1/total\n",
    "    prob2 = count2/total\n",
    "\n",
    "    # Can't call log(0)\n",
    "    if prob1 > 0.0 and prob2 > 0.0:\n",
    "        return -prob1 * math.log(prob1, 2.0) - prob2 * math.log(prob2, 2.0)\n",
    "    elif prob1 > 0.0:\n",
    "        return -prob1 * math.log(prob1, 2.0)\n",
    "    elif prob2 > 0.0:\n",
    "        return -prob2 * math.log(prob2, 2.0)\n",
    "    else:\n",
    "        print ('There was an error computing expected info.')\n",
    "        return 0\n",
    "def computeEntropy(p, e):\n",
    "    entropy = 0.0\n",
    "    for i in range(len(p)):\n",
    "        entropy += p[i] * e[i]\n",
    "    return entropy\n",
    "# Returns a list of the unique values of the given attribute (given by index) in the given examples\n",
    "def uniqueValues(attrIndex, examples):\n",
    "    values = []\n",
    "    for e in examples:\n",
    "        if e[attrIndex] not in values:\n",
    "            values.append(e[attrIndex])\n",
    "    return values\n",
    "def getMostCommonValue(attr, examples, values):\n",
    "    valueCounts = []\n",
    "\n",
    "    for value in values:\n",
    "        valueCount = 0\n",
    "        for example in examples:\n",
    "            if example[attr] == value:\n",
    "                valueCount += 1\n",
    "        valueCounts.append(valueCount)\n",
    "    maxIndex = valueCounts.index(max(valueCounts))\n",
    "    return values[maxIndex]\n",
    "def constructTreeFromFile(filepath):\n",
    "    f = open(filepath, 'r')\n",
    "    attrLine = f.readline()\n",
    "    attributes = [a.strip() for a in attrLine.split(',')]\n",
    "    examples = []\n",
    "    for line in f:\n",
    "        example = [item.strip() for item in line.split(',')]\n",
    "        examples.append(example)\n",
    "    # The last attribute is always the target attribute\n",
    "    return constructDecisionTree(examples, attributes[-1], attributes)\n",
    "# Returns a list of test cases for the decision tree (examples that don't have\n",
    "def parseTestCases(filepath):\n",
    "    f = open(filepath, 'r')\n",
    "    cases = []\n",
    "    for line in f:\n",
    "        case = [item.strip() for item in line.split(',')]\n",
    "        cases.append(case)\n",
    "    return cases\n",
    "def getAttributesFromFile(filepath):\n",
    "    f = open(filepath, 'r')\n",
    "    attrLine = f.readline()\n",
    "    return [a.strip() for a in attrLine.split(',')]\n",
    "trainingPath = input('Please enter the path to a file containing training data:\\n')\n",
    "tree = constructTreeFromFile(trainingPath)\n",
    "tree.printTree()\n",
    "attributes = getAttributesFromFile(trainingPath)\n",
    "attributes.pop(-1)\n",
    "testingPath =   input('Please enter the path to a file containing cases to be tested:\\n')\n",
    "testCases = parseTestCases(testingPath)\n",
    "outcomes = tree.predictOutcome(testCases, attributes)\n",
    "print (outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6184b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
